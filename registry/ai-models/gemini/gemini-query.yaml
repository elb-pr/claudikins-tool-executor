name: gemini-query
server: gemini
category: ai-models
description: No description provided
inputSchema:
  type: object
  properties:
    prompt:
      type: string
      description: The prompt to send to Gemini
    model:
      type: string
      enum:
        - pro
        - flash
      default: pro
      description: The Gemini model to use (pro or flash)
    thinkingLevel:
      type: string
      enum:
        - minimal
        - low
        - medium
        - high
      description: >-
        Reasoning depth: minimal/low for fast responses, medium/high for complex tasks. Pro supports low/high only.
        Flash supports all levels. Default is high.
  required:
    - prompt
  additionalProperties: false
  $schema: http://json-schema.org/draft-07/schema#
example: |-
  // Quick question with fast model
  await gemini["gemini-query"]({
    prompt: "What is the capital of France?",
    model: "flash",
    thinkingLevel: "minimal"
  });

  // Complex analysis with deep reasoning
  await gemini["gemini-query"]({
    prompt: "Analyse the trade-offs between microservices and monolithic architecture for a startup",
    model: "pro",
    thinkingLevel: "high"
  });

  // Code review request
  await gemini["gemini-query"]({
    prompt: "Review this function for potential bugs and suggest improvements: function add(a,b){return a+b}",
    model: "pro"
  });
